{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation\n",
    "Untuk tugas akhir mata kuliah NLP Semester Genap 2018/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-3\n",
    "\n",
    "Spesifikasi model yang dibangun pada _notebook_ ini adalah sebagai berikut :\n",
    "\n",
    "- Data _trainset_ yang digunakan adalah `triple_annotator_agree.csv` dan `single_annotator.csv`.\n",
    "- _Preprocessing_ yang dilakukan pada kalimat adalah ...\n",
    "- _Feature_ yang digunakan adalah ...\n",
    "- Algoritma model yang digunakan adalah ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import Sastrawi\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensuring reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_SEED = 42\n",
    "np.random.seed(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['double_annotator_agree.csv',\n",
       " 'double_annotator_disagree.csv',\n",
       " 'single_annotator.csv',\n",
       " 'triple_annotator_agree.csv',\n",
       " 'triple_annotator_disagree.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = '../dataset/training_set/'\n",
    "filenames = os.listdir(path)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000034</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Di Jepang, manga biasanya serial di majalah ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000129</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Surah ini dinamai Maryam, karena surat ini men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000476</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Rebusan seperti Waterzooi atau Hachee, rebusan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000486</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Permukaan daun mengandung lapisan lilin sehing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000511</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Pemicu yang paling umum antara lain alergen, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kalimat_id        kata sense  \\\n",
       "0     1000034  mengandung  2301   \n",
       "1     1000129  mengandung  2301   \n",
       "2     1000476  mengandung  2301   \n",
       "3     1000486  mengandung  2301   \n",
       "4     1000511  mengandung  2301   \n",
       "\n",
       "                                             kalimat  \n",
       "0  Di Jepang, manga biasanya serial di majalah ma...  \n",
       "1  Surah ini dinamai Maryam, karena surat ini men...  \n",
       "2  Rebusan seperti Waterzooi atau Hachee, rebusan...  \n",
       "3  Permukaan daun mengandung lapisan lilin sehing...  \n",
       "4  Pemicu yang paling umum antara lain alergen, r...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = []\n",
    "\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(path + filename)\n",
    "    training_set.append(df)\n",
    "training_set[3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testing_data.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../dataset/testing_set/'\n",
    "filenames = os.listdir(path)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "      <th>kalimat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>asing</td>\n",
       "      <td>Para pecinta film indonesia atau tv, pasti tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>asing</td>\n",
       "      <td>Pasti telinga kita merasa asing dan aneh mende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>asing</td>\n",
       "      <td>Warga negara asing atau warga negara Persemakm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>asing</td>\n",
       "      <td>Selama lima belas tahun memerintah, Sultan Mah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>asing</td>\n",
       "      <td>Yang kemudian diikuti dengan donat-donat waral...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   word                                            kalimat\n",
       "0   13  asing  Para pecinta film indonesia atau tv, pasti tak...\n",
       "1   19  asing  Pasti telinga kita merasa asing dan aneh mende...\n",
       "2   41  asing  Warga negara asing atau warga negara Persemakm...\n",
       "3   44  asing  Selama lima belas tahun memerintah, Sultan Mah...\n",
       "4  121  asing  Yang kemudian diikuti dengan donat-donat waral..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set = []\n",
    "\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(path + filename)\n",
    "    testing_set.append(df)\n",
    "testing_set[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Choose training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select dataframe from triple_annotator_agree.csv and single_annotator.csv\n",
    "annotator_agree = pd.DataFrame()\n",
    "\n",
    "for i,df in enumerate(training_set):\n",
    "    if i == 0 or i == 3:\n",
    "        annotator_agree = pd.concat([annotator_agree, df], ignore_index=True)\n",
    "\n",
    "annotator_agree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_agree.kata.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>236872</td>\n",
       "      <td>bisa</td>\n",
       "      <td>0101</td>\n",
       "      <td>Penelitian pada tahun 2003 melaporkan bahwa mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>237114</td>\n",
       "      <td>bisa</td>\n",
       "      <td>0101</td>\n",
       "      <td>Pramana ingin menceraikan Anita untuk bisa mer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>240206</td>\n",
       "      <td>bisa</td>\n",
       "      <td>0101</td>\n",
       "      <td>Ia menemukan bahwa dalam unsur tertentu, nukle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>242752</td>\n",
       "      <td>bisa</td>\n",
       "      <td>0101</td>\n",
       "      <td>Maleficent sudah berusaha mencabut kutukannya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>243816</td>\n",
       "      <td>bisa</td>\n",
       "      <td>0101</td>\n",
       "      <td>Walaupun berasal dari keluarga sederhana, Inda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kalimat_id  kata sense                                            kalimat\n",
       "227      236872  bisa  0101  Penelitian pada tahun 2003 melaporkan bahwa mo...\n",
       "228      237114  bisa  0101  Pramana ingin menceraikan Anita untuk bisa mer...\n",
       "229      240206  bisa  0101  Ia menemukan bahwa dalam unsur tertentu, nukle...\n",
       "230      242752  bisa  0101  Maleficent sudah berusaha mencabut kutukannya ...\n",
       "231      243816  bisa  0101  Walaupun berasal dari keluarga sederhana, Inda..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = annotator_agree[annotator_agree.kata == 'bisa']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0101'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sense.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets preprocessing for supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\" Remove stopwords from a text (bahasa).\n",
    "        :param text: the text \n",
    "        :type text: string\n",
    "        :return: a stopwords removed text\n",
    "        :rtype: string\n",
    "    \"\"\"\n",
    "    stopwords = pd.read_csv('../dataset/stopwords.csv')\n",
    "    special_list = []\n",
    "    token = nltk.word_tokenize(text)\n",
    "    token_afterremoval = []\n",
    "    for k in token:\n",
    "        if k not in stopwords and k not in special_list:\n",
    "            token_afterremoval.append(k)\n",
    "    \n",
    "    str_clean = ' '.join(token_afterremoval)\n",
    "    return str_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \"\"\" Normalize a text (lowercase, ).\n",
    "    \"\"\"\n",
    "    normal_txt = text.lower()\n",
    "    normal_txt = re.sub('\\s+', ' ', normal_txt)\n",
    "    normal_txt = normal_txt.strip()\n",
    "    normal_txt = re.sub(r'[^\\w\\s]', '', normal_txt)\n",
    "    \n",
    "    normal_regex = re.compile(r'(.)\\1{1,}', re.IGNORECASE)\n",
    "    normal_txt = normal_regex.sub(r'\\1\\1', normal_txt)\n",
    "    return normal_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(texts):\n",
    "    text_clean = []\n",
    "    for txt in texts:\n",
    "        normal_txt = normalize(txt)\n",
    "        #nosw_txt = remove_stopwords(normal_txt)\n",
    "        text_clean.append(normal_txt)\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['secara anatomi hidung adalah penonjolan pada vertebrata yang mengandung nostril yang menyaring udara untuk pernapasan',\n",
       " 'mandi air yang mengandung belerang untuk pengobatan penyakit kulit',\n",
       " 'dengan terikatnya klathrin membrane sel membentuk vesikel yang mengandung molekul ligan']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get clean texts\n",
    "raw_text = annotator_agree['kalimat']\n",
    "label = annotator_agree['sense'].tolist()\n",
    "\n",
    "clean_text = preprocessing(raw_text)\n",
    "clean_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kalimat_id</th>\n",
       "      <th>kata</th>\n",
       "      <th>sense</th>\n",
       "      <th>kalimat</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000527</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Secara anatomi, hidung adalah penonjolan pada ...</td>\n",
       "      <td>secara anatomi hidung adalah penonjolan pada v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000651</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Mandi air yang mengandung belerang, untuk peng...</td>\n",
       "      <td>mandi air yang mengandung belerang untuk pengo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000770</td>\n",
       "      <td>mengandung</td>\n",
       "      <td>2301</td>\n",
       "      <td>Dengan terikatnya klathrin, membrane sel membe...</td>\n",
       "      <td>dengan terikatnya klathrin membrane sel memben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001199</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>Dalam menapaki karier di gedung parlemen, Toto...</td>\n",
       "      <td>dalam menapaki karier di gedung parlemen totok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001330</td>\n",
       "      <td>mengejar</td>\n",
       "      <td>2802</td>\n",
       "      <td>Ini juga memberi EMC pengalaman dan wawasan ma...</td>\n",
       "      <td>ini juga memberi emc pengalaman dan wawasan ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kalimat_id        kata sense  \\\n",
       "0     1000527  mengandung  2301   \n",
       "1     1000651  mengandung  2301   \n",
       "2     1000770  mengandung  2301   \n",
       "3     1001199    mengejar  2802   \n",
       "4     1001330    mengejar  2802   \n",
       "\n",
       "                                             kalimat  \\\n",
       "0  Secara anatomi, hidung adalah penonjolan pada ...   \n",
       "1  Mandi air yang mengandung belerang, untuk peng...   \n",
       "2  Dengan terikatnya klathrin, membrane sel membe...   \n",
       "3  Dalam menapaki karier di gedung parlemen, Toto...   \n",
       "4  Ini juga memberi EMC pengalaman dan wawasan ma...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  secara anatomi hidung adalah penonjolan pada v...  \n",
       "1  mandi air yang mengandung belerang untuk pengo...  \n",
       "2  dengan terikatnya klathrin membrane sel memben...  \n",
       "3  dalam menapaki karier di gedung parlemen totok...  \n",
       "4  ini juga memberi emc pengalaman dan wawasan ma...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_agree['clean_text'] = clean_text\n",
    "annotator_agree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kata                                                 mengandung\n",
       "clean_text    secara anatomi hidung adalah penonjolan pada v...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['kata', 'clean_text']\n",
    "annotator_agree[feature_cols].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_basic_features(sentence_terms, index):\n",
    "    \"\"\" Compute some very basic word features.\n",
    "        :param sentence_terms: [w1, w2, ...] \n",
    "        :type sentence_terms: list\n",
    "        :param index: the index of the word \n",
    "        :type index: int\n",
    "        :return: dict containing features\n",
    "        :rtype: dict\n",
    "    \"\"\"\n",
    "    term = sentence_terms[index]\n",
    "    sentence_len len(sentence_terms)\n",
    "    return {\n",
    "        'term': term,\n",
    "        'word-2': '' if index == 0 or index == 1 else sentence_terms[index - 2],\n",
    "        'word-1': '' if index == 0 else sentence_terms[index - 1],\n",
    "        'word+1': '' if index == sentence_len - 1 else sentence_terms[index + 1],\n",
    "        'word+2': '' if index == sentence_len - 1 or index == sentence_len - 2 else sentence_terms[index + 1],        \n",
    "        \n",
    "        \n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence_terms) - 1,\n",
    "        'is_capitalized': term[0].upper() == term[0],\n",
    "        'is_all_caps': term.upper() == term,\n",
    "        'is_all_lower': term.lower() == term,\n",
    "        'prefix-1': term[0],\n",
    "        'prefix-2': term[:2],\n",
    "        'prefix-3': term[:3],\n",
    "        'suffix-1': term[-1],\n",
    "        'suffix-2': term[-2:],\n",
    "        'suffix-3': term[-3:],\n",
    "        'prev_word': '' if index == 0 else sentence_terms[index - 1],\n",
    "        'next_word': '' if index == len(sentence_terms) - 1 else sentence_terms[index + 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dataset(tagged_sentences):\n",
    "    \"\"\"\n",
    "    Split tagged sentences to X and y datasets and append some basic features.\n",
    "    :param tagged_sentences: a list of POS tagged sentences\n",
    "    :param tagged_sentences: list of list of tuples (term_i, tag_i)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for pos_tags in tagged_sentences:\n",
    "        for index, (term, class_) in enumerate(pos_tags):\n",
    "            # Add basic NLP features for each sentence term\n",
    "            X.append(add_basic_features(untag(pos_tags), index))\n",
    "            y.append(class_)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
